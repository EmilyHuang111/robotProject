from flask import Flask, render_template_string, request, jsonify
from threading import Thread
import time
import os
import re
import subprocess
import tempfile
import requests

from adafruit_servokit import ServoKit
from gtts import gTTS

# ===================== Keys / Config =====================
DEEPGRAM_API_KEY = os.environ.get("DEEPGRAM_API_KEY")
if not DEEPGRAM_API_KEY:
    print("[WARN] DEEPGRAM_API_KEY not set; set it with: export DEEPGRAM_API_KEY='YOUR_KEY'")

# OpenAI client (uses the modern SDK)
try:
    from openai import OpenAI
    _openai_client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
except Exception as e:
    _openai_client = None
    print("OpenAI client not available:", e)

# ===================== TTS =====================
def speak_async(text: str):
    """Speak text in the background using gTTS + mpg123."""
    if not text:
        return
    def _run():
        try:
            tts = gTTS(text=text, lang='en')
            with tempfile.NamedTemporaryFile(delete=True, suffix='.mp3') as fp:
                tts.save(fp.name)
                subprocess.run(['mpg123', fp.name],
                               stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        except Exception as e:
            print("TTS error:", e)
    Thread(target=_run, daemon=True).start()

# ===================== Language model =====================
def lm_reply(user_text: str) -> str:
    if not _openai_client:
        return "Language model is not configured. Please set OPENAI_API_KEY."
    try:
        resp = _openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system",
                 "content": "You are a helpful, concise assistant controlling a small quadruped robot. Keep replies short."},
                {"role": "user", "content": user_text},
            ],
            temperature=0.4,
            max_tokens=300,
        )
        return (resp.choices[0].message.content or "").strip()
    except Exception as e:
        return f"Error contacting language model: {e}"

# ===================== Deepgram STT =====================
def deepgram_transcribe(audio_bytes: bytes, mimetype: str = "audio/webm") -> str:
    if not DEEPGRAM_API_KEY:
        return ""

    url = "https://api.deepgram.com/v1/listen"
    headers = {
        "Authorization": f"Token {DEEPGRAM_API_KEY}",
        "Content-Type": mimetype
    }
    params = {
        "model": "nova-2",
        "smart_format": "true",
        "language": "en-US",
        "punctuate": "true"
    }

    try:
        r = requests.post(url, headers=headers, params=params, data=audio_bytes, timeout=30)
        r.raise_for_status()
        jd = r.json()

        try:
            return jd["results"]["channels"][0]["alternatives"][0]["transcript"].strip()
        except Exception:
            pass

        if isinstance(jd, dict) and "transcript" in jd:
            return (jd["transcript"] or "").strip()

        return ""
    except Exception as e:
        print("Deepgram error:", e)
        return ""

# ===================== Flask & ServoKit =====================
app = Flask(__name__)
kit = ServoKit(channels=16)

# ===================== Channel Mapping (your wiring) =====================
LEG1F_CHANNEL = 0
LEG1B_CHANNEL = 1
LEG2F_CHANNEL = 8
LEG2B_CHANNEL = 9
LEG3F_CHANNEL = 2
LEG3B_CHANNEL = 3
LEG4F_CHANNEL = 10
LEG4B_CHANNEL = 11

LF_HIP, LF_KNEE = LEG1F_CHANNEL, LEG1B_CHANNEL
RF_HIP, RF_KNEE = LEG2F_CHANNEL, LEG2B_CHANNEL
LR_HIP, LR_KNEE = LEG3F_CHANNEL, LEG3B_CHANNEL
RR_HIP, RR_KNEE = LEG4F_CHANNEL, LEG4B_CHANNEL

ALL_HIPS  = [LF_HIP, RF_HIP, LR_HIP, RR_HIP]
ALL_KNEES = [LF_KNEE, RF_KNEE, LR_KNEE, RR_KNEE]

# Diagonal pairs
DIAG_A = [(LF_HIP, LF_KNEE), (RR_HIP, RR_KNEE)]  # LF + RR
DIAG_B = [(RF_HIP, RF_KNEE), (LR_HIP, LR_KNEE)]  # RF + LR

# ===================== Tuning =====================
INVERT_HIP  = {LF_HIP: False, RF_HIP: True,  LR_HIP: False, RR_HIP: True}
INVERT_KNEE = {LF_KNEE: False, RF_KNEE: True, LR_KNEE: False, RR_KNEE: True}

HIP_NEUTRAL = 90
HIP_FWD     = 65
HIP_BACK    = 145

KNEE_DOWN   = 124
KNEE_UP     = 86

PRESS_DELTA   = +8
LIGHTEN_DELTA = -6

RAMP_STEP   = 3
RAMP_DELAY  = 0.01
DWELL       = 0.12
TROT_DWELL  = 0.12

# ===================== Movement flags =====================
movement_flag = {
    'forward':   False,  # UI "Forward" uses locked-sync trot
    'backward':  False,
    'left':      False,
    'right':     False,
    'trot':      False,
    'trot_sync': False,
}

# ===================== Helpers =====================
def _apply_invert(ch, angle, invert_map):
    return 180 - angle if invert_map.get(ch, False) else angle

def _current_angle(ch, default_raw, invert_map):
    a = kit.servo[ch].angle
    return int(a) if a is not None else _apply_invert(ch, default_raw, invert_map)

def _ramp_to(ch, target_raw, invert_map, step=RAMP_STEP, delay=RAMP_DELAY):
    target = _apply_invert(ch, target_raw, invert_map)
    cur = _current_angle(ch, target_raw, invert_map)
    if cur == target:
        kit.servo[ch].angle = target
        return
    sgn = 1 if target > cur else -1
    for a in range(cur, target, sgn * step):
        kit.servo[ch].angle = a
        time.sleep(delay)
    kit.servo[ch].angle = target

def _ramp_sync(ch_list, target_raw_list, invert_map, step=RAMP_STEP, delay=RAMP_DELAY):
    curs, targs = [], []
    for ch, t_raw in zip(ch_list, target_raw_list):
        t = _apply_invert(ch, t_raw, invert_map)
        c = _current_angle(ch, t_raw, invert_map)
        curs.append(c)
        targs.append(t)

    deltas = [abs(t - c) for c, t in zip(curs, targs)]
    max_steps = 0 if not deltas else max((d + step - 1) // step for d in deltas)

    for _ in range(max_steps):
        for idx, ch in enumerate(ch_list):
            c, t = curs[idx], targs[idx]
            if c == t:
                continue
            sgn = 1 if t > c else -1
            move = min(step, abs(t - c))
            c_new = c + sgn * move
            kit.servo[ch].angle = c_new
            curs[idx] = c_new
        time.sleep(delay)
    for ch, t in zip(ch_list, targs):
        kit.servo[ch].angle = t

def set_hip(ch, angle):  _ramp_to(ch, angle, INVERT_HIP)
def set_knee(ch, angle): _ramp_to(ch, angle, INVERT_KNEE)

def set_hip_pair(pair, angle):
    chs = [pair[0][0], pair[1][0]]
    _ramp_sync(chs, [angle, angle], INVERT_HIP)

def set_knee_pair(pair, angle):
    chs = [pair[0][1], pair[1][1]]
    _ramp_sync(chs, [angle, angle], INVERT_KNEE)

def set_hips_all_sync(angle):
    _ramp_sync(ALL_HIPS, [angle]*4, INVERT_HIP)

def set_knees_all_sync(angle):
    _ramp_sync(ALL_KNEES, [angle]*4, INVERT_KNEE)

# ===================== Posture =====================
def plant_all():
    set_knees_all_sync(KNEE_DOWN)

def hips_all(angle=HIP_NEUTRAL):
    set_hips_all_sync(angle)

def setup():
    print("Setup: knees down, hips neutral...")
    plant_all()
    hips_all(HIP_NEUTRAL)
    time.sleep(0.2)

# ===================== Motion building blocks =====================
def leg_lift(hip, knee):           set_knee(knee, KNEE_UP)
def leg_lower(hip, knee):          set_knee(knee, KNEE_DOWN)
def leg_swing_forward(hip, knee):  set_hip(hip, HIP_FWD)
def leg_swing_backward(hip, knee): set_hip(hip, HIP_BACK)

def weight_shift_for_pair(swing_pair):
    stance_pair = DIAG_B if swing_pair == DIAG_A else DIAG_A
    set_knee_pair(stance_pair, KNEE_DOWN + PRESS_DELTA)
    set_knee_pair(swing_pair,   KNEE_DOWN + LIGHTEN_DELTA)
    time.sleep(TROT_DWELL)

def clear_weight_shift():
    set_knees_all_sync(KNEE_DOWN)

# ===================== Crawl (used for backward) =====================
def setup_pose_bias_back():
    plant_all()
    hips_all(HIP_NEUTRAL)
    _ramp_sync(ALL_HIPS, [ (HIP_NEUTRAL + HIP_BACK)//2 ]*4, INVERT_HIP)
    time.sleep(0.2)

def swing_backward_sequence(hip, knee):
    weight_shift_for_pair(DIAG_B if (hip, knee) in DIAG_A else DIAG_A)
    leg_lift(hip, knee);   time.sleep(DWELL)
    leg_swing_backward(hip, knee); time.sleep(DWELL)
    leg_lower(hip, knee);  time.sleep(DWELL)
    clear_weight_shift()

def stance_push_all_forward():
    set_hips_all_sync(HIP_FWD);  time.sleep(DWELL)

def crawl_step_backward(order):
    for hip, knee in order:
        swing_backward_sequence(hip, knee)
        stance_push_all_forward()

def walk_backward_loop():
    print("Crawl (backward)")
    setup_pose_bias_back()
    order = [(LF_HIP, LF_KNEE), (RR_HIP, RR_KNEE), (RF_HIP, RF_KNEE), (LR_HIP, LR_KNEE)]
    while movement_flag['backward']:
        crawl_step_backward(order)
    setup(); print("Backward stopped.")

# ===================== Locked‑sync trot (Forward) =====================
def trot_step_forward_sync(stance_pair, swing_pair):
    weight_shift_for_pair(swing_pair)
    set_knee_pair(swing_pair, KNEE_UP); time.sleep(TROT_DWELL)
    set_hip_pair(swing_pair, HIP_FWD);  time.sleep(TROT_DWELL)
    set_knee_pair(swing_pair, KNEE_DOWN); time.sleep(TROT_DWELL)
    clear_weight_shift()
    set_hips_all_sync(HIP_BACK); time.sleep(TROT_DWELL)

def trot_forward_loop_sync():
    print("Locked‑sync trot (forward)")
    setup_pose_bias_back()
    stance, swing = DIAG_A, DIAG_B
    while movement_flag['trot_sync']:
        trot_step_forward_sync(stance, swing)
        stance, swing = swing, stance
    setup(); print("Trot (sync) stopped.")

# ===================== Simple in‑place turns =====================
def turn_left_loop():
    print("Turning left (in place)...")
    plant_all(); hips_all(HIP_NEUTRAL); time.sleep(0.2)
    while movement_flag['left']:
        _ramp_sync([LF_HIP, LR_HIP, RF_HIP, RR_HIP],
                   [HIP_BACK, HIP_BACK, HIP_FWD, HIP_FWD], INVERT_HIP)
        time.sleep(DWELL)
        set_knee(RF_KNEE, KNEE_UP); time.sleep(DWELL*0.6); set_knee(RF_KNEE, KNEE_DOWN)
        set_knee(LR_KNEE, KNEE_UP); time.sleep(DWELL*0.6); set_knee(LR_KNEE, KNEE_DOWN)
        hips_all(HIP_NEUTRAL); time.sleep(DWELL*0.5)
    setup(); print("Left turn stopped.")

def turn_right_loop():
    print("Turning right (in place)...")
    plant_all(); hips_all(HIP_NEUTRAL); time.sleep(0.2)
    while movement_flag['right']:
        _ramp_sync([RF_HIP, RR_HIP, LF_HIP, LR_HIP],
                   [HIP_BACK, HIP_BACK, HIP_FWD, HIP_FWD], INVERT_HIP)
        time.sleep(DWELL)
        set_knee(LF_KNEE, KNEE_UP); time.sleep(DWELL*0.6); set_knee(LF_KNEE, KNEE_DOWN)
        set_knee(RR_KNEE, KNEE_UP); time.sleep(DWELL*0.6); set_knee(RR_KNEE, KNEE_DOWN)
        hips_all(HIP_NEUTRAL); time.sleep(DWELL*0.5)
    setup(); print("Right turn stopped.")

# ===================== Natural-language parsing =====================
COMMAND_PATTERNS = [
    (r'\b(stop|halt|park)\b',                        lambda: ('stop',)),
    (r'\b(trot sync|sync trot|locked trot)\b',       lambda: ('forward',)),  # map to forward
    (r'\bforward\b',                                 lambda: ('forward',)),
    (r'\bbackward|reverse\b',                        lambda: ('backward',)),
    (r'\bleft\b',                                    lambda: ('left',)),
    (r'\bright\b',                                   lambda: ('right',)),
    (r'\bneutral|home|reset\b',                      lambda: ('diag/neutral',)),
]

def parse_robot_command(text: str):
    text = (text or "").lower().strip()
    if text.startswith("robot "):
        text = text.split(" ", 1)[1]
    for pattern, builder in COMMAND_PATTERNS:
        if re.search(pattern, text):
            return builder()[0]
    return None

def execute_robot_action(action: str):
    if action == 'stop':
        return stop()
    elif action == 'forward':
        return forward()
    elif action == 'backward':
        return backward()
    elif action == 'left':
        return left()
    elif action == 'right':
        return right()
    elif action == 'diag/neutral':
        return diag_neutral()
    else:
        return "Unknown action."

# ===================== UI (speech bubbles + mic button) =====================
HTML = '''
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Quadruped Controller</title>
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <style>
    :root{
      --bg: #f4f5f7;
      --card: #ffffff;
      --text: #1f2937;
      --muted: #6b7280;
      --shadow: 0 8px 24px rgba(0,0,0,.06);
      --radius: 12px;

      /* Neutral palette */
      --neutral: #f1f3f5;
      --neutral-hover: #e9ecef;
      --neutral-border: #dfe3e8;
      --neutral-text: #2c3e50;

      /* Blue accents (for focus + assistant bubble) */
      --blue: #2563eb;                 /* assistant bubble */
      --blue-600: #2563eb;
      --blue-glow: rgba(59,130,246,.35);   /* input focus ring */
      --blue-border: #3b82f6;

      /* Safety */
      --danger: #b91c1c;
      --danger-hover: #991b1b;
    }

    *{box-sizing:border-box}
    body{
      font-family: ui-sans-serif, -apple-system, Segoe UI, Roboto, Helvetica, Arial;
      background: linear-gradient(180deg, #f8f9fa 0%, var(--bg) 100%);
      color: var(--text);
      margin: 0; padding: 28px;
      display: flex; justify-content: center;
    }
    .container{ width: min(1080px, 100%); display: grid; gap: 18px; }

    .card{
      background: var(--card);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      border: 1px solid #eef0f2;
      padding: 18px;
    }
    .header{ display:flex; align-items:center; justify-content:space-between; gap:12px; }
    .title{ font-size: 20px; font-weight: 700; letter-spacing: .2px; }
    .controls{
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(160px, 1fr));
      gap: 12px; margin-top: 12px;
    }

    /* Neutral buttons */
    .btn{
      appearance:none; cursor:pointer; user-select:none;
      border:1px solid var(--neutral-border);
      padding: 12px 14px; border-radius: 10px;
      font-size: 16px; font-weight: 600; letter-spacing:.2px;
      background: var(--neutral); color: var(--neutral-text);
      transition: transform .06s ease, box-shadow .18s ease, background .18s ease, border-color .18s ease, filter .18s ease;
      box-shadow: 0 2px 10px rgba(0,0,0,.05);
      outline: none;
    }
    .btn:hover{ background: var(--neutral-hover); transform: translateY(-1px); }
    .btn:active{ transform: translateY(0); filter: saturate(.98); }
    .btn:focus-visible{ box-shadow: 0 0 0 4px var(--blue-glow); border-color: var(--blue-border); }

    /* Stop (safety) */
    .btn-danger{ background: var(--danger); color:#fff; border-color: var(--danger); }
    .btn-danger:hover{ background: var(--danger-hover); border-color: var(--danger-hover); }

    /* Chat */
    #chatbox{
      height: 320px;
      border: 1px solid #e5e7eb;
      border-radius: 12px;
      padding: 12px;
      overflow: auto;
      background: #fcfcfd;
      display: flex;
      flex-direction: column;
      gap: 8px;
    }

    .row{ display:flex; gap:10px; align-items:center; }

    .chat-input{
      flex:1;
      padding: 12px 14px;
      border: 1px solid #dadada;
      border-radius: 12px;
      font-size: 16px;
      outline:none;
      background:#fff;
      transition: box-shadow .18s ease, border-color .18s ease;
    }
    /* BLUE glow on focus */
    .chat-input:focus{
      border-color: var(--blue-border);
      box-shadow: 0 0 0 4px var(--blue-glow);
    }

    /* Speech bubbles */
    .msg{
      max-width: 75%;
      padding: 10px 12px;
      border-radius: 14px;
      line-height: 1.35;
      word-wrap: break-word;
      box-shadow: 0 1px 4px rgba(0,0,0,.06);
    }
    .msg.user{
      margin-left: auto;
      background: var(--neutral);
      color: var(--neutral-text);
      border: 1px solid var(--neutral-border);
    }
    .msg.bot{
      margin-right: auto;
      background: var(--blue);
      color: #ffffff;
      border: 1px solid var(--blue-600);
    }
    .msg.system{
      margin-right: auto;
      background: #eef2ff;
      color: #1e3a8a;
      border: 1px solid #c7d2fe;
    }

    /* Icon buttons (send + mic) */
    .icon-btn{
      display: inline-flex; align-items:center; justify-content:center;
      width: 46px; height: 46px;
      border-radius: 50%;
      border: 1px solid transparent;
      background: #3a3a3a; color: #fff;
      box-shadow: 0 2px 10px rgba(0,0,0,.10);
      cursor: pointer;
      transition: transform .06s ease, background .2s ease, box-shadow .2s ease, border-color .2s ease;
      outline: none;
    }
    .icon-btn:hover{ background: #2f2f2f; transform: translateY(-1px); }
    .icon-btn:active{ transform: translateY(0); }
    .icon-btn:focus-visible{ box-shadow: 0 0 0 4px var(--blue-glow); border-color: var(--blue-border); }
    .icon{ width: 22px; height: 22px; display:block; }

    /* Mic recording state */
    .icon-btn.mic.active{
      background: #ef4444; /* red while recording */
    }
  </style>
</head>
<body>
  <div class="container">

    <!-- Controls -->
    <div class="card">
      <div class="header">
        <div class="title">Robot Movement</div>
      </div>
      <div class="controls">
        <button class="btn" onclick="sendCmd('forward')">Forward</button>
        <button class="btn" onclick="sendCmd('backward')">Backward</button>
        <button class="btn" onclick="sendCmd('left')">Left</button>
        <button class="btn" onclick="sendCmd('right')">Right</button>
        <button class="btn btn-danger" onclick="sendCmd('stop')">Stop</button>
      </div>
    </div>

    <!-- Chat -->
    <div class="card">
      <div class="header"><div class="title">Chat</div></div>
      <div id="chatbox"></div>
      <div class="row" style="margin-top:10px;">
        <input id="msg" class="chat-input" type="text" placeholder="Ask a question or give a command" />
        <!-- Mic button (toggle record) -->
        <button id="micBtn" class="icon-btn mic" onclick="toggleRec()" aria-label="Record voice">
          <svg class="icon" viewBox="0 0 24 24" fill="none" aria-hidden="true">
            <path d="M12 3a3 3 0 00-3 3v6a3 3 0 006 0V6a3 3 0 00-3-3z" stroke="white" stroke-width="2" stroke-linecap="round"/>
            <path d="M5 11a7 7 0 0014 0M12 18v3" stroke="white" stroke-width="2" stroke-linecap="round"/>
          </svg>
        </button>
        <!-- Icon-only send button (arrow up) -->
        <button class="icon-btn" onclick="ask()" aria-label="Send">
          <svg class="icon" viewBox="0 0 24 24" fill="none" aria-hidden="true">
            <path d="M12 19V5M12 5l-6 6M12 5l6 6" stroke="white" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          </svg>
        </button>
      </div>
    </div>

  </div>

  <script>
    function sendCmd(path){
      fetch('/' + path);
      appendBubble('system', 'Executing: ' + path);
    }

    function appendBubble(kind, text){
      const box = document.getElementById('chatbox');
      const div = document.createElement('div');
      div.className = 'msg ' + (kind || 'bot');
      div.textContent = text;
      box.appendChild(div);
      box.scrollTop = box.scrollHeight;
    }

    async function ask(){
      const input = document.getElementById('msg');
      const text = input.value.trim();
      if(!text) return;
      appendBubble('user', text);
      input.value = '';

      const resp = await fetch('/ask', {
        method:'POST',
        headers:{'Content-Type':'application/json'},
        body: JSON.stringify({text})
      });
      const data = await resp.json();
      if (data.robot_action) appendBubble('system', 'Executing: ' + data.robot_action);
      appendBubble('bot', data.reply || '(no response)');
    }

    // Enter to send
    document.getElementById('msg').addEventListener('keydown', (e)=>{
      if(e.key === 'Enter') ask();
    });

    // ======== Voice (MediaRecorder -> /voice_ask) ========
    let mediaRecorder = null, chunks = [], streamRef = null, recording = false;

    function pickSupportedMime(){
      const candidates = [
        'audio/webm;codecs=opus',
        'audio/webm',
        'audio/mp4' // fallback on Safari
      ];
      for (const t of candidates){
        if (MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(t)) return t;
      }
      return '';
    }

    async function toggleRec(){
      if (recording){
        stopRec();
      } else {
        await startRec();
      }
    }

    async function startRec(){
      const micBtn = document.getElementById('micBtn');
      try {
        const mimeType = pickSupportedMime();
        streamRef = await navigator.mediaDevices.getUserMedia({ audio: true });
        mediaRecorder = new MediaRecorder(streamRef, mimeType ? { mimeType } : undefined);
        chunks = [];
        mediaRecorder.ondataavailable = e => { if (e.data && e.data.size > 0) chunks.push(e.data); };
        mediaRecorder.onstop = async () => {
          const chosenType = mediaRecorder.mimeType || 'audio/webm';
          const blob = new Blob(chunks, { type: chosenType });
          chunks = [];
          await sendVoiceBlob(blob);
          cleanupStream();
        };
        mediaRecorder.start();
        recording = true;
        micBtn.classList.add('active');
      } catch (err) {
        appendBubble('system', 'Microphone error: ' + err);
        cleanupStream();
      }
    }

    function stopRec(){
      const micBtn = document.getElementById('micBtn');
      if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
      } else {
        cleanupStream(); // ensure UI resets even if not recording
      }
      recording = false;
      micBtn.classList.remove('active');
    }

    function cleanupStream(){
      if (streamRef){
        streamRef.getTracks().forEach(t => t.stop());
        streamRef = null;
      }
      mediaRecorder = null;
    }

    async function sendVoiceBlob(blob){
      const form = new FormData();
      // filename can be generic; the browser sets the correct Content-Type for the part
      form.append('audio', blob, 'voice');
      try {
        const resp = await fetch('/voice_ask', { method: 'POST', body: form });
        const data = await resp.json();
        if (data.transcript) appendBubble('user', data.transcript);
        if (data.robot_action) appendBubble('system', 'Executing: ' + data.robot_action);
        appendBubble('bot', data.reply || '(no response)');
      } catch (e){
        appendBubble('system', 'Voice send error: ' + e);
      }
    }
  </script>
</body>
</html>
'''

@app.route('/')
def index():
    return render_template_string(HTML)

# ---- Start/Stop endpoints ----
def _stop_all_flags():
    for k in movement_flag.keys():
        movement_flag[k] = False

# Forward = locked‑sync trot
@app.route('/forward')
def forward():
    if any(movement_flag.values()):
        _stop_all_flags(); time.sleep(0.1)
    movement_flag['trot_sync'] = True
    Thread(target=trot_forward_loop_sync, daemon=True).start()
    return "Moving forward (locked-sync trot)..."

@app.route('/backward')
def backward():
    if any(movement_flag.values()):
        _stop_all_flags(); time.sleep(0.1)
    movement_flag['backward'] = True
    Thread(target=walk_backward_loop, daemon=True).start()
    return "Moving backward (crawl gait)..."

@app.route('/left')
def left():
    if any(movement_flag.values()):
        _stop_all_flags(); time.sleep(0.1)
    movement_flag['left'] = True
    Thread(target=turn_left_loop, daemon=True).start()
    return "Turning left..."

@app.route('/right')
def right():
    if any(movement_flag.values()):
        _stop_all_flags(); time.sleep(0.1)
    movement_flag['right'] = True
    Thread(target=turn_right_loop, daemon=True).start()
    return "Turning right..."

@app.route('/stop')
def stop():
    _stop_all_flags()
    setup()
    return "Stopping and parking neutral."

# Neutral pose command used in parser
@app.route('/diag_neutral')
def diag_neutral():
    setup()
    return "Neutral posture set."

# Text chat
@app.route('/ask', methods=['POST'])
def ask():
    data = request.get_json(force=True, silent=True) or {}
    text = (data.get('text') or "").strip()

    action = parse_robot_command(text)
    robot_msg = None
    if action:
        robot_msg = execute_robot_action(action)

    reply = lm_reply(text)
    speak_async(reply)
    return jsonify({"reply": reply, "robot_action": action, "robot_message": robot_msg})

# Voice chat (kept and wired to mic button)
@app.route('/voice_ask', methods=['POST'])
def voice_ask():
    f = request.files.get('audio')
    if not f:
        return jsonify({"error": "No audio provided"}), 400

    audio_bytes = f.read()
    mimetype = f.mimetype or "audio/webm"

    transcript = deepgram_transcribe(audio_bytes, mimetype=mimetype)
    if not transcript:
        reply = "I didn't catch that. Please try again."
        speak_async(reply)
        return jsonify({"transcript": "", "reply": reply, "robot_action": None})

    action = parse_robot_command(transcript)
    robot_msg = None
    if action:
        robot_msg = execute_robot_action(action)

    reply = lm_reply(transcript)
    speak_async(reply)
    return jsonify({"transcript": transcript, "reply": reply, "robot_action": action, "robot_message": robot_msg})

# ===================== Main =====================
if __name__ == "__main__":
    setup()
    # Optional: per-servo calibration
    # for ch in [LF_HIP, RF_HIP, LR_HIP, RR_HIP, LF_KNEE, RF_KNEE, LR_KNEE, RR_KNEE]:
    #     kit.servo[ch].set_pulse_width_range(500, 2500)
    app.run(host='0.0.0.0', port=5000)
